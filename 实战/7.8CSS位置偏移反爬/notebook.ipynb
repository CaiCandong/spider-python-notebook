{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wonder\n",
      "家 白 清 风\n",
      "法 老 的 宠 妃 终 结 篇 （ 上 下 册 ）\n",
      "二 知 ） 己 士 为 全 （ 册\n",
      "那 些 年 ， 我 们 一 起 追 的 女 孩\n",
      "三 城 ） 倾 全 非 我 （ 册\n",
      "些 那 儿 朝 明 事\n",
      "书 忘 我 和 你 的 笑\n",
      "波 全 小 卷 王 一 第 集\n",
      "动 怦 然 心\n",
      "龙枪编年史（全3册）\n",
      "） 枪 奇 （ 龙 传 全 三 册\n",
      "黎 明 街 之\n",
      "认 知 心 理 学 及 其 启 示\n",
      "银河帝国2：基地与帝国\n",
      "国 基 帝 地 河 银 ：\n",
      "四 - 级 解 全 材 文 年 教 语 学 小 下\n",
      "越界言论（第3卷）\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from pyquery import PyQuery as pq\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "browser.get('https://antispider3.scrape.center/')\n",
    "WebDriverWait(browser, 10) \\\n",
    "    .until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.item')))\n",
    "html = browser.page_source\n",
    "doc = pq(html)\n",
    "names = doc('.item .name')\n",
    "for name in names.items():\n",
    "    print(name.text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "清白家风\n",
      "法老的宠妃终结篇（上下册）\n",
      "士为知己（全二册）\n",
      "那些年，我们一起追的女孩\n",
      "非我倾城（全三册）\n",
      "明朝那些事儿\n",
      "我和你的笑忘书\n",
      "王小波全集第一卷\n",
      "怦然心动\n",
      "\n",
      "龙枪传奇（全三册）\n",
      "黎明之街\n",
      "认知心理学及其启示\n",
      "\n",
      "银河帝国：基地\n",
      "小学教材全解-四年级语文下\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from pyquery import PyQuery as pq\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import re\n",
    "\n",
    "# 通过排序获得正确的结果\n",
    "def parse_name(name_html):\n",
    "    chars = name_html('.char')\n",
    "    items = []\n",
    "    for char in chars.items():\n",
    "        items.append({\n",
    "            'text': char.text().strip(),\n",
    "            'left': int(re.search('(\\d+)px', char.attr('style')).group(1))\n",
    "        })\n",
    "    items = sorted(items, key=lambda x: x['left'], reverse=False)\n",
    "    return ''.join([item.get('text') for item in items])\n",
    "\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "browser.get('https://antispider3.scrape.center/')\n",
    "WebDriverWait(browser, 10) \\\n",
    "    .until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.item')))\n",
    "html = browser.page_source\n",
    "doc = pq(html)\n",
    "names = doc('.item .name')\n",
    "\n",
    "for name_html in names.items():\n",
    "    name = parse_name(name_html)\n",
    "    print(name)\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wonder\n",
      "清白家风\n",
      "法老的宠妃终结篇（上下册）\n",
      "士为知己（全二册）\n",
      "那些年，我们一起追的女孩\n",
      "非我倾城（全三册）\n",
      "明朝那些事儿\n",
      "我和你的笑忘书\n",
      "王小波全集第一卷\n",
      "怦然心动\n",
      "龙枪编年史（全3册）\n",
      "龙枪传奇（全三册）\n",
      "黎明之街\n",
      "认知心理学及其启示\n",
      "银河帝国2：基地与帝国\n",
      "银河帝国：基地\n",
      "小学教材全解-四年级语文下\n",
      "越界言论（第3卷）\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from pyquery import PyQuery as pq\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import re\n",
    "\n",
    "\n",
    "def parse_name(name_html):\n",
    "    has_whole = name_html('.whole')\n",
    "    if has_whole:\n",
    "        return name_html.text()\n",
    "    else:\n",
    "        chars = name_html('.char')\n",
    "        items = []\n",
    "        for char in chars.items():\n",
    "            items.append({\n",
    "                'text': char.text().strip(),\n",
    "                'left': int(re.search('(\\d+)px', char.attr('style')).group(1))\n",
    "            })\n",
    "        items = sorted(items, key=lambda x: x['left'], reverse=False)\n",
    "        return ''.join([item.get('text') for item in items])\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "browser.get('https://antispider3.scrape.center/')\n",
    "WebDriverWait(browser, 10) \\\n",
    "    .until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.item')))\n",
    "html = browser.page_source\n",
    "doc = pq(html)\n",
    "names = doc('.item .name')\n",
    "\n",
    "for name_html in names.items():\n",
    "    name = parse_name(name_html)\n",
    "    print(name)\n",
    "browser.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4a847150c17a56e8ab8e8e7872ca30cb83471eb1df49153297cb018a7672186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
