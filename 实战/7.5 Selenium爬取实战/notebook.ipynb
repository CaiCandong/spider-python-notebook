{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化浏览器对象  \n",
    "IDM命令\n",
    "https://blog.csdn.net/MuoYangoRen/article/details/79954776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# chrome 浏览器位置\n",
    "# 驱动参数配置\n",
    "options = Options()\n",
    "# option.add_argument('headless')  # 后台运行\n",
    "options.binary_location = r\"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\"\n",
    "\n",
    "# chrome 浏览器驱动位置\n",
    "chrome_service = Service(r'C:\\Users\\root\\anaconda3\\Scripts\\chromedriver.exe')\n",
    "\n",
    "\n",
    "browser = webdriver.Chrome(\n",
    "    options=options, \n",
    "    service =chrome_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "        format ='%(asctime)s-%(levelname)s: %(message)s')\n",
    "index_url = \"https://spa2.scrape.center/page/{page}\"\n",
    "time_out = 10 \n",
    "total_page = 10 \n",
    "wait= WebDriverWait(browser ,time_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.webdriver.common.by  import By\n",
    "\n",
    "def scrape_page(url,condition,locator):\n",
    "    logging.info(\"scaping %s\",url)\n",
    "    try:\n",
    "        browser.get(url)\n",
    "        wait.until(condition(locator))\n",
    "    except TimeoutException:\n",
    "        logging.error(\"error occurred while scaping %s\",url,exc_info=True)\n",
    "\n",
    "\n",
    "def scrape_index(page):\n",
    "    url = index_url.format(page=page)\n",
    "    scrape_page(url,condition=EC.visibility_of_all_elements_located,locator=(By.CSS_SELECTOR,\"#index .item\"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "def parse_index():\n",
    "\n",
    "    # elements = browser.find_elements_by_css_selector('#index .item .name')\n",
    "    elements = browser.find_elements(By.CSS_SELECTOR,'#index .item .name')\n",
    "    for element in elements:\n",
    "        href = element.get_attribute('href')\n",
    "        yield urljoin(index_url, href)\n",
    "\n",
    "\n",
    "def scrape_detail(url):\n",
    "    scrape_page(url, condition=EC.visibility_of_element_located,\n",
    "                locator=(By.TAG_NAME, 'h2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_detail():\n",
    "    url = browser.current_url\n",
    "    name = browser.find_element(By.TAG_NAME,'h2').text\n",
    "    categories = [element.text for element in browser.find_elements(By.CSS_SELECTOR,'.categories button span')]\n",
    "    cover = browser.find_element(By.CSS_SELECTOR,'.cover').get_attribute('src')\n",
    "    score = browser.find_element(By.CLASS_NAME,'score').text\n",
    "    drama = browser.find_element(By.CSS_SELECTOR,'.drama p').text\n",
    "    return {\n",
    "        'url': url,\n",
    "        'name': name,\n",
    "        'categories': categories,\n",
    "        'cover': cover,\n",
    "        'score': score,\n",
    "        'drama': drama\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os \n",
    "RESULTS_DIR = 'results'\n",
    "\n",
    "os.path.exists(RESULTS_DIR) or os.makedirs(RESULTS_DIR)\n",
    "\n",
    "def save_data(data):\n",
    "    name = data.get('name')\n",
    "    data_path = f'{RESULTS_DIR}/{name}.json'\n",
    "    json.dump(data, open(data_path, 'w', encoding='utf-8'), ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(1, total_page + 1):\n",
    "    scrape_index(page)\n",
    "    detail_urls = parse_index()\n",
    "    for detail_url in list(detail_urls):\n",
    "        logging.info('get detail url %s', detail_url)\n",
    "        scrape_detail(detail_url)\n",
    "        detail_data = parse_detail()\n",
    "        logging.info('detail data %s', detail_data)\n",
    "        save_data(detail_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4a847150c17a56e8ab8e8e7872ca30cb83471eb1df49153297cb018a7672186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
